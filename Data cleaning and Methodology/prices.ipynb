{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculos Índice\n",
    "\n",
    "Aquí hare todo el plotting the los precios del indice, aunque este a medias creo la base para solo tener que cambiar el archivo del cual saco la informacion y apa ya esta. Dejandolo Listo para el siguiente paso.\n",
    "Seleccionar los parámetros de los precios, crear la fórmula para el cálculo de los pesos y crear la función que calcule el índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import eikon as ek\n",
    "\n",
    "ek.set_app_key('f5c3af98ce3e4070aba80b9bc465cd82b9624cfc')\n",
    "\n",
    "path = '/Users/ruben/Documents/MASTER/TFM/data/'\n",
    "a = pd.read_csv(path + 'draft1.csv')\n",
    "a1=a.drop(['Unnamed: 0'], axis=1)\n",
    "a1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.sort_values(by = 'Company Market Cap')[['Name', 'TRBC Industry Group Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, err = ek.get_data(a1.RICS.to_list(),['TR.CLOSEPRICE.date','TR.CLOSEPRICE', 'TR.CompanyMarketCap'],\n",
    "            {'SDate':'2018-04-20', 'Curn':'EUR', 'EDate':'2023-04-20', 'Adjusted':'1'}) # En euros para evitar problemas de divisa y ajustado para introducir eventos de los stocks\n",
    "print('total: '+c.__len__(), 'Dates: '+ c['Date'].unique())\n",
    "c # What if weekly to avoid data loss? or Drop Data that has less than 45 instruments?\n",
    "\n",
    "\n",
    "# AQUÍ METEMOS EL FLOAT-RATE POR EMPRESA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame(c, columns = ['Instrument', 'Date', 'Close Price','rent_diaria', 'Company Market Cap', 'weight'])\n",
    "total_cap = []\n",
    "\n",
    "for i in c['Date'].unique(): # Calculo de la capitalización total de cada fecha\n",
    "   total_cap.append(sum(c[c['Date']==i]['Company Market Cap']))\n",
    "\n",
    "full = pd.DataFrame( columns = ['Date', 'total_cap'])\n",
    "full['total_cap']= total_cap\n",
    "full['Date'] = c['Date'].unique()\n",
    "\n",
    "for i, v in zip(c['Date'], range(len(c))): # Calculo de los pesos de cada stock en cada fecha\n",
    "    c['weight'].iloc[v]=c[c['Date']==i]['Company Market Cap'][v]/sum(full[full['Date']==i]['total_cap'])\n",
    "\n",
    "index = pd.MultiIndex.from_frame(c[['Date','weight']])\n",
    "c_index = c.set_index(index, inplace= False)\n",
    "c_index.sort_index(level=['Date', 'weight'], inplace=True, ascending=[True, False])\n",
    "c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_frame(c[['Instrument', 'Date']])\n",
    "b_index = c.set_index(index, inplace= False)\n",
    "b_index.sort_index(level=['Instrument', 'Date'], inplace=True, ascending=[True, True])\n",
    "b_index = pd.DataFrame(b_index ,columns = ['Instrument', 'Date', 'Close Price', 'Company Market Cap', 'weight', 'rent_diaria'])\n",
    "\n",
    "b=[]\n",
    "for i in b_index['Instrument'].unique(): # rentabilidad diaria y aportada al indice\n",
    "    b.append(b_index[b_index['Instrument']==i]['Close Price'].pct_change())\n",
    "\n",
    "for i, v in zip(b_index['Instrument'].unique(), range(len(b_index['Instrument'].unique()))):\n",
    "    b_index.loc[i, 'rent_diaria']=b[v].values\n",
    "\n",
    "b_index['rent_index'] = b_index['weight']*b_index['rent_diaria']\n",
    "b_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnew =b_index.reset_index(drop=True, inplace=False)\n",
    "index = pd.MultiIndex.from_frame(b_index[['Date','Instrument']])\n",
    "bnew.set_index(index, inplace=True)\n",
    "bnew.sort_index(level=['Date', 'Instrument'], inplace=True, ascending=[True, True])\n",
    "\n",
    "full =  pd.DataFrame(full, columns = ['Date', 'total_cap', 'tot_rent'])\n",
    "for i, v in zip(bnew['Date'].unique(), range(len(bnew['Date'].unique()))):\n",
    "    full['tot_rent'].iloc[v]=bnew.loc[i]['rent_index'].sum()\n",
    "full # rentabilidad y capitalización diaria del índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full =  pd.DataFrame(full, columns = ['Date', 'total_cap', 'tot_rent', 'net value'])\n",
    "full['net value'].iloc[0]=1000 # Valor inicial del índice\n",
    "for i in range(len(full)): # Valor neto del índice\n",
    "    if IndexError:\n",
    "        pass\n",
    "    else:\n",
    "        full['net value'].iloc[i+1]=full['net value'].iloc[i]*(1+full['tot_rent'].iloc[i+1])\n",
    "\n",
    "b_index.to_csv(path + 'b_index.csv')\n",
    "full.to_csv(path + 'full.csv')\n",
    "\n",
    "full"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segunda parte, pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full[full['net value']==full['net value'].min()] # Mínimo valor del índice -> Covid jaja "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['Date'] = pd.to_datetime(full['Date'])\n",
    "full['Date'] = full['Date'].dt.strftime('%Y-%m-%d')\n",
    "full['Date'] = pd.to_datetime(full['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eikon as ek\n",
    "\n",
    "ek.set_app_key('f5c3af98ce3e4070aba80b9bc465cd82b9624cfc')\n",
    "\n",
    "import pandas as pd\n",
    "import pyfolio as pf\n",
    "import numpy as np\n",
    "# Silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path = '/Users/ruben/Documents/MASTER/TFM/data/'\n",
    "#full = pd.read_csv(path+'full.csv', parse_dates=['Date'])\n",
    "#bac = full.set_index('Date')\n",
    "#bac.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "#bac['net value'].resample('A').ffill().pct_change() # Rentabilidad Anual / Mensual / Semanal del índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rentabilidades diarias de los índices mundiales -> ready en rets.csv (con rets adj)\n",
    "rics = ['.FTSE', '.STOXX50E']\n",
    "bench_rets = ek.get_timeseries(rics, fields = 'CLOSE',start_date='2018-04-20', end_date='2023-04-20', interval='daily')\n",
    "a = pd.DataFrame(bench_rets.pct_change())\n",
    "test = bac.merge(a, on = 'Date', how='left')\n",
    "tics = ['.SX5EESG','.FT4GDGLOB100']\n",
    "bench_rets_1 = ek.get_timeseries(tics, fields = 'CLOSE',start_date='2018-04-20', end_date='2023-04-20', interval='daily')\n",
    "b = pd.DataFrame(bench_rets_1.pct_change())\n",
    "test = test.merge(b, on = 'Date', how='left')\n",
    "dics = ['.MIWO00000PUS', '.NDX']\n",
    "bench_rets_2 = ek.get_timeseries(dics, fields = 'CLOSE',start_date='2018-04-20', end_date='2023-04-20', interval='daily')\n",
    "c = pd.DataFrame(bench_rets_2.pct_change())\n",
    "test = test.merge(c, on = 'Date', how='left')\n",
    "bics = ['.SXWESGP']\n",
    "bench_rets_3 = ek.get_timeseries(bics, fields = 'CLOSE',start_date='2018-04-20', end_date='2023-04-20', interval='daily')\n",
    "d = pd.DataFrame(bench_rets_3.pct_change())\n",
    "test = test.merge(d, on = 'Date', how='left')\n",
    "test.rename(columns = {'CLOSE' : '.SXWESGP'}, inplace=True)\n",
    "rets = test[['tot_rent','.FT4GDGLOB100','.STOXX50E','.FTSE', '.STOXX50','.SXWESGP', '.MIWO00000PUS', '.NDX']]\n",
    "rets = rets.ffill(axis  = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.drop(columns = ['Unnamed: 0'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rets with less than 40 comp per day \n",
    "rets_null = pd.read_csv(path+'index_adj_null.csv', parse_dates=['Date'])\n",
    "rets_null.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "rets_null['Date']= rets_null['Date'].dt.strftime('%Y-%m-%d')\n",
    "rets_null.rename(columns = {'tot_rent_adj' : 'tot_rent_adj_null'}, inplace=True)\n",
    "\n",
    "rets_null['Date'] = pd.to_datetime(rets_null['Date'], yearfirst=True)\n",
    "rets_null.set_index('Date', inplace=True)\n",
    "rets_null.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets_null['Date'] = pd.to_datetime(rets_null['Date'], yearfirst=True)\n",
    "rets_null.set_index('Date', inplace=True)\n",
    "rets_null.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sector mapping\n",
    "beta = pd.read_csv(path + 'gold.csv', parse_dates=['Date'])\n",
    "\n",
    "sector_map = beta[['Instrument', 'TRBC Economic Sector Name']].set_index('Instrument').to_dict()\n",
    "sector_map['TRBC Economic Sector Name']\n",
    "pf.timeseries.annual_return(rets['tot_rent_adj'], period='daily')\n",
    "pf.timeseries.forecast_cone_bootstrap(rets['tot_rent_adj'], 30, cone_std=(1.0, 1.5, 2.0), starting_value=1, num_samples=1000, random_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tear Sheet w Bench and updated rets\n",
    "rets = pd.read_csv(path+'rets.csv', parse_dates=['Date'])\n",
    "rets.set_index('Date', inplace=True)\n",
    "pf.create_full_tear_sheet(rets_null['tot_rent_adj_null'], benchmark_rets=rets['.STOXX50']) # Análisis de la rentabilidad del índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Returns Chart w Benchmark\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pf.create_interesting_times_tear_sheet(rets['tot_rent_adj'], benchmark_rets=rets['.STOXX50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats for the Index in table format\n",
    "stats = pf.timeseries.perf_stats(rets['tot_rent_adj'])\n",
    "pd.DataFrame(stats, columns=['Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carbon emissions data \n",
    "\n",
    "cc_index = pd.read_csv(path+'weight_ind.csv', parse_dates=['Date'])\n",
    "c, err = ek.get_data(cc_index.Instrument.unique().tolist(),['TR.AnalyticGHGEmissionsScope1and2and3(Period=FY0).date', 'TR.AnalyticGHGEmissionsScope1and2and3(Period=FY0)'])\n",
    "c\n",
    "\n",
    "# Intensidad de emisiones del Índice -> usar esto para los demás índices y comparar la intensidad de emisiones entre todos \n",
    "#cc_index['Date'] = cc_index['Date'].dt.strftime('%Y-%m-%d')\n",
    "index = pd.MultiIndex.from_frame(cc_index[['Instrument', 'Date']])\n",
    "b_index = cc_index.set_index(index) # cc_index -> not indexed // b_index -> indexed\n",
    "b_index.drop(columns = ['Instrument', 'Date','Unnamed: 0'], inplace=True)\n",
    "\n",
    "means  = pd.DataFrame(data = b_index.index.get_level_values(0).unique(), columns = ['Instrument', 'weight_adj'])\n",
    "\n",
    "for i, v in zip(means['Instrument'], range(len(means['Instrument']))): # avg means of weights for 2022\n",
    "    means.iloc[v]['weight_adj'] = b_index.loc[i].loc['2022']['weight_adj'].mean()\n",
    "\n",
    "boi = c.merge(means, on = 'Instrument', how='left')\n",
    "boi['weighted emissions in MILL'] = boi['GHG Emissions Scope 1,2,3 to Revenue USD in million']*boi['weight_adj']\n",
    "boi.sum() # suma de las emisiones a revenue ponderadas por peso del índice en millones de USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orden de los stocks por peso en el índice\n",
    "means.sort_values(by = 'weight_adj', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index lists w returns\n",
    "index_list = ['.FTSE', '.STOXX50', '.STOXX50E', '.FT4GDGLOB100', '.SXWESGP', '.MIWO00000PUS', '.NDX', '.IBEX35']\n",
    "d, err = ek.get_data(index_list, ['TR.IndexName','TR.IndexMktCapVendor','TR.IndexTotalReturn1Yr','TR.IndexTotalReturn3Yr','TR.IndexTotalReturn5Yr'])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index constituents and weights for indices (pesos no encontrados hay que mirar más -> comentarlo en PPT)\n",
    "index_con = ['.SXWESGP','.FTSE', '.STOXX50', '.STOXX50E', '.NDX', '.FT4GDGLOB100']\n",
    "teta=pd.DataFrame(columns = ['Index'])\n",
    "for i in index_con:\n",
    "    ab, err = ek.get_data(i, ['TR.IndexConstituentRIC','TR.IndexConstituentWeightPercent'])\n",
    "    teta.insert(0, str(i) ,ab['Constituent RIC'])\n",
    "    teta.insert(0, str(i+' weight') ,ab['Weight percent'])\n",
    "teta.drop('Index', axis=1, inplace=True)\n",
    "teta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alineación con la disminución del 7% de emisiones anuales para cumplir con el acuerdo de Paris de Índices y Mío\n",
    "import numpy as np\n",
    "index_con = ['.SXWESGP','.FTSE', '.STOXX50', '.STOXX50E', '.NDX']\n",
    "l = []\n",
    "l.extend(range(6))\n",
    "pcts = pd.DataFrame(columns = ['empty','indice', 'pct alineado'])\n",
    "pcts['empty']=l\n",
    "\n",
    "for i, k in zip(index_con, range(6)):\n",
    "    ba, err = ek.get_data(teta[i].dropna().to_list(), ['TR.AnalyticGHGEmissionsIntensityScope1and2and3ParisAligned(Period=FY0)'])\n",
    "    ba = ba.groupby('GHG Emissions Intensity Scope 1,2,3 Paris Agreement Aligned').count()\n",
    "    pcts['indice'].iloc[k]=i\n",
    "    pcts['pct alineado'].iloc[k]=np.round((ba.loc['True']['Instrument']/ba['Instrument'].sum())*100, 2)\n",
    "\n",
    "ba, err = ek.get_data(cc_index['Instrument'].unique().tolist(), ['TR.AnalyticGHGEmissionsIntensityScope1and2and3ParisAligned(Period=FY0)'])\n",
    "ba = ba.groupby('GHG Emissions Intensity Scope 1,2,3 Paris Agreement Aligned').count()\n",
    "pcts['indice'].iloc[5]='own'\n",
    "pcts['pct alineado'].iloc[5]=np.round((ba.loc['True']['Instrument']/ba['Instrument'].sum())*100, 2)\n",
    "\n",
    "pcts.drop('empty', axis = 1, inplace = True) # % de empresas alineadas con el acuerdo de Paris por índice\n",
    "pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de los datos base del índice\n",
    "a1 = pd.read_csv(path + 'draft1.csv')\n",
    "index2 = pd.MultiIndex.from_frame(a1[['TRBC Economic Sector Name', 'TRBC Industry Group Name']])\n",
    "b2 = a1.set_index(index2, inplace=False).rename(columns = {'RICS':'Instrument'})\n",
    "b2.sort_index(level=['TRBC Economic Sector Name', 'TRBC Industry Group Name'], inplace=True, ascending=[True, True])\n",
    "b3 = b2.merge(boi, on = 'Instrument', how='left')\n",
    "main = b3[['Name', 'Instrument','weight_adj', 'TRBC Economic Sector Name', 'Company Market Cap','GHG Emissions Scope 1,2,3 to Revenue USD in million']]\n",
    "main.sort_values(by = 'weight_adj', ascending=False, inplace=True)\n",
    "main\n",
    "b3.to_csv(path + 'b3.csv') # Datos completos del Índice con pesos media de 2022\n",
    "main.to_csv(path + 'main.csv') # Datos base del índice con pesos media de 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peso y Emisiones de cada sector en el índice\n",
    "\n",
    "b3 = pd.read_csv(path + 'b3.csv')\n",
    "indus_peso = pd.DataFrame(b3.groupby(['TRBC Economic Sector Name'])['weight_adj'].sum().sort_values(ascending=False), columns = ['weight_adj'])\n",
    "indus_emi = pd.DataFrame(b3.groupby(['TRBC Economic Sector Name'])['GHG Emissions Scope 1,2,3 to Revenue USD in million'].sum())\n",
    "display(indus_peso,indus_emi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peso por sector\n",
    "import seaborn as sns \n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set_context(\"poster\", font_scale=0.8)\n",
    "sns.barplot(x=indus_peso['weight_adj'], y=indus_peso.index, data=indus_peso, palette='Reds_d')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamos datos para calcular la rentabilidad por sector \n",
    "cols = b3[['Instrument', 'TRBC Economic Sector Name', 'TRBC Industry Group Name']]\n",
    "b_index['rent_index_adj'] = b_index['weight_adj']*b_index['rent_diaria']\n",
    "rent_sector = b_index.merge(cols, on = 'Instrument', how='left')\n",
    "rent_sector.set_index(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = pd.MultiIndex.from_frame(cc_index[['Instrument', 'Date']])\n",
    "b_index = cc_index.set_index(index) # cc_index -> not indexed // b_index -> indexed\n",
    "b_index['rent_index_adj'] = b_index['weight_adj']*b_index['rent_diaria']\n",
    "b_index.drop(columns = ['Unnamed: 0'], inplace=True)\n",
    "b_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo real de las rentabilidades diarias por sector -> Podemos hacer Stacked Area Chart con esto\n",
    "cols = b3[['Instrument', 'TRBC Economic Sector Name', 'TRBC Industry Group Name']]\n",
    "\n",
    "rent_sector = b_index.merge(cols, on = 'Instrument', how='left')\n",
    "rent_sector.set_index(index, inplace=True)\n",
    "rent_sector.drop(columns = ['Instrument'], inplace=True)\n",
    "rent_sector.reset_index(inplace=True)\n",
    "\n",
    "rent_sector['Date'] = pd.to_datetime(rent_sector['Date'])\n",
    "rent_sector['Date'] = rent_sector['Date'].dt.strftime('%Y-%m-%d')\n",
    "index2 = pd.MultiIndex.from_frame(rent_sector[['TRBC Economic Sector Name','Date']])\n",
    "rent_sector.set_index(index2, inplace=True)\n",
    "rent_sector.sort_index(level=['TRBC Economic Sector Name','Date'], inplace=True, ascending=[True, True])\n",
    "rent_sector.drop(columns = ['TRBC Economic Sector Name', 'Date'], inplace=True)\n",
    "\n",
    "dates =  rent_sector.index.get_level_values(1).unique()\n",
    "dates1 = rent_sector.index.get_level_values(1).unique()\n",
    "for i in range (9): \n",
    "    dates = dates.append(dates1)\n",
    "alpha = pd.DataFrame(dates, columns = ['Date','TRBC Economic Sector Name', 'tot_rent_adj', 'tot_cap_adj'])\n",
    "loc = 0\n",
    "for i in rent_sector.index.get_level_values(0).unique():\n",
    "    for k in range(len(alpha['Date'].unique())):\n",
    "        alpha['TRBC Economic Sector Name'].iloc[loc]=i\n",
    "        loc = loc + 1\n",
    "loc = 0\n",
    "index = pd.MultiIndex.from_frame(alpha[['TRBC Economic Sector Name','Date']])\n",
    "alpha.set_index(index, inplace=True)\n",
    "beta = alpha.drop(columns = ['TRBC Economic Sector Name', 'Date'])\n",
    "beta.sort_index(level=['TRBC Economic Sector Name','Date'], inplace=True, ascending=[True, True])\n",
    "b = []\n",
    "for k in rent_sector.index.get_level_values(0).unique():\n",
    "    temp = rent_sector.loc[k]\n",
    "    for i, v in zip(alpha.index.get_level_values(1).unique(), range(len(beta))):\n",
    "        try:\n",
    "            beta['tot_rent_adj'].iloc[loc]=temp.loc[i]['rent_index_adj'].sum()\n",
    "            b.append(temp.loc[i]['rent_index_adj'].sum()) # Este es el que vale lo de arriba es basura\n",
    "        except KeyError:\n",
    "            beta['tot_rent_adj'].iloc[loc]= np.nan\n",
    "            \n",
    "        loc = loc + 1\n",
    "casi = pd.DataFrame(b, columns = ['rent_sector_adj'], index = rent_sector.index.unique())\n",
    "casi\n",
    "#gamma # rentabilidad y capitalización diaria del índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renatbilidad acumulada por Sector y por Compañía de manera ajena al índice\n",
    "d=[]\n",
    "e = []\n",
    "c = []\n",
    "for i in casi.index.get_level_values(0).unique():\n",
    "    e.append(i)\n",
    "    c = (1 + casi.loc[i].rent_sector_adj).cumprod() - 1\n",
    "    d.append(c)\n",
    "\n",
    "best = pd.DataFrame(d, index = e)\n",
    "rets_sec = pd.DataFrame(best['2023-04-20'])\n",
    "rets_sec.sort_values(by = '2023-04-20', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "f=[]\n",
    "g = []\n",
    "c =[]\n",
    "for i in b_index.index.get_level_values(0).unique():\n",
    "    g.append(i)\n",
    "    c = (1 + b_index.loc[i].rent_index_adj).cumprod() - 1\n",
    "    f.append(c[-1])\n",
    "cata = pd.DataFrame(f, index = g)\n",
    "rets_comp = pd.DataFrame(cata)\n",
    "rets_comp.rename(columns = {0 : '2023-04-20'}, inplace=True)\n",
    "rets_comp.sort_values(by = '2023-04-20', ascending=False, inplace=True)\n",
    "display(rets_sec, rets_comp.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#rets_comp.reset_index(inplace=True)\n",
    "#rets_comp.rename(columns = {'2023-04-20' : 'Rentabilidad Acumulada', 'index': 'Instrument'}, inplace=True)\n",
    "#rets_comp.drop(columns = ['level_0'], inplace=True)\n",
    "rets_comp.merge(beta[['Name','Instrument']], on = 'Instrument', how='left').set_index('Name').drop(columns='Instrument').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCT de tamaños de empresas\n",
    "vol_cap = b3.groupby('Market Cap Category').count()['ISIN']\n",
    "l = vol_cap[0]/vol_cap.sum()\n",
    "m = vol_cap[1]/vol_cap.sum()\n",
    "s = vol_cap[2]/vol_cap.sum()\n",
    "\n",
    "print ('Large Cap: '+str(l), '%', 'Mid Cap: '+str(m), '%' ,'Small Cap: '+str(s), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 basado en last pesos índice -> antes y ahora (2023)\n",
    "testo = b_index.reset_index(drop= True).set_index(['Date'])\n",
    "a = testo.loc['2023-04-20'][['Instrument','weight_adj']].rename(columns = {'weight_adj':'weight_adj_2023'})\n",
    "b = testo.loc['2023-04-20'][['Instrument','Company Market Cap']].rename(columns = {'Company Market Cap':'mkt_cap_2023_EUR'})\n",
    "b3 = b3.merge(b, on = 'Instrument', how='left')\n",
    "beta = b3.merge(a, on = 'Instrument', how='left')\n",
    "print(beta[['Name', 'weight_adj_2023', 'TRBC Economic Sector Name']].sort_values(by = 'weight_adj_2023', ascending=False).set_index('Name').head(10).sum())\n",
    "\n",
    "testo = b_index.reset_index(drop= True).set_index(['Date'])\n",
    "a = testo.loc['2023-04-20'][['Instrument','weight']].rename(columns = {'weight':'weight_2023'})\n",
    "beta = beta.merge(a, on = 'Instrument', how='left')\n",
    "print(beta[['Name', 'weight_2023', 'TRBC Economic Sector Name']].sort_values(by = 'weight_2023', ascending=False).set_index('Name').head(10).sum())\n",
    "display(beta[['Name', 'weight_adj_2023', 'TRBC Economic Sector Name']].sort_values(by = 'weight_adj_2023', ascending=False).set_index('Name').head(10),\n",
    "        beta[['Name', 'weight_2023', 'TRBC Economic Sector Name']].sort_values(by = 'weight_2023', ascending=False).set_index('Name').head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta.drop(columns = ['Unnamed: 0', 'mkt_cap_2023_EUR_y' ], inplace = True)\n",
    "beta.rename(columns = {'mkt_cap_2023_EUR_x':'mkt_cap_2023_EUR'}, inplace=True)\n",
    "beta.to_csv(path + 'gold.csv') # Datos completos del Índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = pd.read_csv(path + 'gold.csv', parse_dates=['Date'])\n",
    "\n",
    "sector_map = beta[['Instrument', 'TRBC Economic Sector Name']].set_index('Instrument').to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights by Sector for 2023 New vs Old\n",
    "display(beta.groupby('TRBC Economic Sector Name')[['weight_adj_2023', 'TRBC Economic Sector Name']].sum().sort_values(by='weight_adj_2023', ascending=False).rename(columns = {'weight_adj_2023':'weights'}, inplace = False),\n",
    "        beta.groupby('TRBC Economic Sector Name')[['weight_2023', 'TRBC Economic Sector Name']].sum().sort_values(by='weight_2023', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de los pesos de cada sector en el índice\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "\n",
    "beta['log_cap_2023'] = np.log(beta['mkt_cap_2023_EUR'])\n",
    "\n",
    "# drawing the plot\n",
    "sns.scatterplot(data = beta, x= 'log_cap_2023' , y = 'weight_adj_2023', hue = 'TRBC Economic Sector Name')\n",
    "sns.set(rc={'figure.figsize':(20,10)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ek.get_data(b3.Instrument.unique().tolist(),['TR.HeadquartersCountry','TR.ExchangeCountry','CURRENCY'])\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cont = countries[0].groupby('Country of Headquarters').count().sort_values(by = 'Instrument', ascending=False)\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set_context(\"poster\", font_scale=0.8)\n",
    "sns.barplot(x=plot_cont.Instrument, y=plot_cont.index, data=plot_cont, palette='Reds_d')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = c.groupby(c['Date'])['Instrument'].count() == 45\n",
    "mask[mask==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = c[c['Date']=='2018-04-27T00:00:00Z']['Instrument'].to_list()\n",
    "a1[a1['RICS'].isin(ab)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
